{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous SGD updates using Distributed Cache Redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create spot instances\n",
    "2. Mount EFS (Not required for our project)\n",
    "3. Start redis server in all the instances and create a cluster\n",
    "4. Pull the code from github repo (https://github.com/SrujithPoondla/vanilla-hogwild.git)\n",
    "5. If need to divide the dataset between the nodes run the specific cell\n",
    "6. Run the scripts to start training\n",
    "7. After training ends close the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_setup import *\n",
    "from argparse import ArgumentParser\n",
    "import boto3\n",
    "import os \n",
    "sys.argv = ['foo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--is-redis'], dest='is_redis', nargs=0, const=True, default=True, type=None, choices=None, help='Choose whether the model to be trained using redis or not.If not using Redis, model will be trained on single process', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser(description='Asynchronous SGD updates using Redis')\n",
    "parser.add_argument('--n-nodes', type=int, default=1, metavar='N',\n",
    "                    help='how many aws instances to start')\n",
    "parser.add_argument('--is-redis', action='store_true', default = True,\n",
    "                    help=\"Choose whether the model to be trained using redis or not.\"\n",
    "                    \"If not using Redis, model will be trained on single process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()\n",
    "vpc_name='vpc-1b056b60'\n",
    "args.n_nodes = 4\n",
    "n_instances = args.n_nodes\n",
    "instance_type = 'm4.10xlarge'\n",
    "ami_sr = 'ami-0b991974'\n",
    "a_zone = 'us-east-1a'\n",
    "\n",
    "if args.n_nodes is 2 and args.is_redis:\n",
    "    print('Cant create a cluster with 2 redis nodes. Chose either a 3 node cluster or single instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Existing VPC by tag name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ec2.Vpc(id='vpc-1b056b60')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpc = get_vpc(vpc_name); vpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create EFS (if you haven't already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efs_tag = f'{vpc_name}-efs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efs = create_efs(efs_tag, vpc, performance_mode='maxIO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request Spot instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_name = f'{vpc_name}-instance'\n",
    "# Recommend a high compute instance as we need to do multi-threaded resizing later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot price: 0.601800, Bid price: 1.8054\n"
     ]
    }
   ],
   "source": [
    "spot_price = get_spot_prices()[instance_type]\n",
    "bid_price = \"%.4f\" % (float(spot_price)*3)\n",
    "print(f'Spot price: {spot_price}, Bid price: {bid_price}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_specs = LaunchSpecs(vpc, instance_type=instance_type, ami= ami_sr,availability_zone=a_zone).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch_specs['BlockDeviceMappings'][0]['Ebs']['VolumeSize'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BlockDeviceMappings': [{'DeviceName': '/dev/sda1',\n",
       "   'Ebs': {'DeleteOnTermination': True,\n",
       "    'VolumeSize': 20,\n",
       "    'VolumeType': 'gp2'}}],\n",
       " 'ImageId': 'ami-0b991974',\n",
       " 'InstanceType': 'm4.10xlarge',\n",
       " 'KeyName': 'aws-key-spot-instance',\n",
       " 'NetworkInterfaces': [{'AssociatePublicIpAddress': True,\n",
       "   'DeviceIndex': 0,\n",
       "   'Groups': ['sg-2624da6f'],\n",
       "   'SubnetId': 'subnet-10d9d04d'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launch_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "4\n",
      "Created keypair\n",
      "Waiting on spot fullfillment...\n",
      "Fulfillment completed. InstanceId: i-0ac17f00f29b3a07a\n",
      "Waiting on spot fullfillment...\n",
      "Fulfillment completed. InstanceId: i-0cd12e7fccad34e74\n",
      "Waiting on spot fullfillment...\n",
      "Fulfillment completed. InstanceId: i-0e9fe1c86bf4c30ea\n",
      "Waiting on spot fullfillment...\n",
      "Fulfillment completed. InstanceId: i-014728ebfc5b5aca1\n",
      "Rebooting...\n",
      "Completed. SSH:  ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@34.228.215.131\n",
      "Completed. SSH:  ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@18.232.132.227\n",
      "Completed. SSH:  ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@35.168.12.100\n",
      "Completed. SSH:  ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@54.172.189.24\n",
      "[ec2.Instance(id='i-014728ebfc5b5aca1'), ec2.Instance(id='i-0e9fe1c86bf4c30ea'), ec2.Instance(id='i-0ac17f00f29b3a07a'), ec2.Instance(id='i-0cd12e7fccad34e74')]\n"
     ]
    }
   ],
   "source": [
    "ec2 = boto3.resource('ec2')\n",
    "filters = [\n",
    "    {\n",
    "        'Name': 'instance-state-name',\n",
    "        'Values': ['running']\n",
    "    }\n",
    "]\n",
    "# filter the instances based on filters() above\n",
    "ec2_instances = list(ec2.instances.filter(Filters=filters))\n",
    "instances = []\n",
    "for instance in ec2_instances:\n",
    "    instances.append(instance)\n",
    "print(instances)\n",
    "instances_to_request = n_instances-len(instances)\n",
    "print(instances_to_request)\n",
    "instances = create_multiple_spot_instance(instance_name, launch_specs,instance_count=args.n_nodes, spot_price=bid_price)\n",
    "print(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@34.228.215.131', 'ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@18.232.132.227', 'ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@35.168.12.100', 'ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@54.172.189.24'] ['34.228.215.131', '18.232.132.227', '35.168.12.100', '54.172.189.24'] ['10.0.0.7', '10.0.0.8', '10.0.0.9', '10.0.0.6']\n"
     ]
    }
   ],
   "source": [
    "# instance = get_instance(instance_name); instance\n",
    "ssh_commands = []\n",
    "public_ip_list = []\n",
    "private_ip_list = []\n",
    "for instance in instances:\n",
    "    # for each instance, append to lists\n",
    "    private_ip_list.append(instance.private_ip_address)\n",
    "    public_ip_list.append(instance.public_ip_address)\n",
    "    ssh_commands.append(get_ssh_command(instance))\n",
    "print(ssh_commands, public_ip_list, private_ip_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminating instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for instance in instances:\n",
    "#     print(instance.terminate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activate Conda Environment in all the instances and check whether we need to create a cluster or not. Then start redis using conf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Exception: timed out Retrying...\n",
      "Exception: timed out Retrying...\n",
      "Connected!\n",
      "b\"No local changes to save\\nAlready up-to-date.\\nYour branch is up-to-date with 'origin/stable'.\\ncifar10_data\\nlargescale.yml\\nminiconda3\\nmnist_data\\nredis-4.0.9\\nredis-conf\\nredis-ml\\nvanilla-hogwild\\n\"\n",
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "b\"No local changes to save\\nAlready up-to-date.\\nYour branch is up-to-date with 'origin/stable'.\\ncifar10_data\\nlargescale.yml\\nminiconda3\\nmnist_data\\nredis-4.0.9\\nredis-conf\\nredis-ml\\nvanilla-hogwild\\n\"\n",
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Exception: [Errno None] Unable to connect to port 22 on 35.168.12.100 Retrying...\n"
     ]
    }
   ],
   "source": [
    "# for client,ip in zip(clients,private_ip_list):\n",
    "#     if 'redis' not in run_command(client,'tmux ls'):\n",
    "#         redis = TmuxSession(client, 'redis-sess')\n",
    "#     run_command(client, 'cd ~/vanilla-hogwild && git stash && git pull && git checkout stable')\n",
    "#     if (args.n_nodes >= 3):\n",
    "#         redis.run_command('rm dump.rdb && rm appendonly.aof && rm nodes-6379.conf')\n",
    "#         redis.run_command('echo bind '+ip+'>> ~/redis-conf/redis_cluster.conf')\n",
    "#         print(redis.run_command('nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis_cluster.conf &'))\n",
    "#         redis.run_command('-d')\n",
    "#     else:\n",
    "#         redis.run_command('echo bind '+ip+'>> ~/redis-conf/redis_cluster.conf')\n",
    "#         redis.run_command('rm dump.rdb && rm appendonly.aof && rm nodes-6379.conf')\n",
    "#         print(redis.run_command('~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis.conf'))\n",
    "#         redis.run_command('-d')\n",
    "\n",
    "# for client,ip in zip(clients,private_ip_list):\n",
    "#     run_command(client, 'cd ~/vanilla-hogwild && git stash && git pull && git checkout stable')\n",
    "#     if (args.n_nodes >= 3):\n",
    "#         run_command(client,'cd /home/ubuntu/ && rm dump.rdb && rm appendonly.aof && rm nodes-6379.conf')\n",
    "#         run_command(client,'echo bind '+ip+'>> ~/redis-conf/redis_cluster.conf')\n",
    "#         print(run_command(client, 'nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis_cluster.conf &'))\n",
    "#     else:\n",
    "#         run_command(client,'cd /home/ubuntu/ && rm dump.rdb && rm appendonly.aof && rm nodes-6379.conf')\n",
    "#         print(run_command(client, 'nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis.conf &'))\n",
    "\n",
    "commands = ['cd ~/vanilla-hogwild', 'git stash', 'git pull' ,'git checkout stable',\n",
    "            'rm -rf ~/redis-data', 'cd ~','ls' ,'mkdir redis-data']\n",
    "\n",
    "for instance,pr_ip in zip(instances,private_ip_list):\n",
    "    client = connect_to_instance(instance)\n",
    "    if (args.n_nodes >= 3):\n",
    "        indep_commands = ['echo bind '+pr_ip+'>> ~/redis-conf/redis_cluster.conf',\n",
    "                          'echo requirepass lsmldeeplearning >> ~/redis-conf/redis_cluster.conf',\n",
    "            'nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis_cluster.conf >\\\n",
    "                          /home/ubuntu/redis-data/redis-log.out &']\n",
    "    else:\n",
    "        indep_commands = ['echo requirepass lsmldeeplearning >> ~/redis-conf/redis.conf','nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis.conf > \\\n",
    "                          /home/ubuntu/redis-data/redis-log.out &']\n",
    "    commands = commands + indep_commands\n",
    "    inp, out,err = client.exec_command(\"\\n\".join(commands))\n",
    "#     sleep(5)\n",
    "    inp.write('\\n')\n",
    "    inp.flush()\n",
    "    output = out.read()\n",
    "    # Close down\n",
    "    out.close()\n",
    "    inp.close()\n",
    "    client.close()\n",
    "    print(output)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create redis cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.n_nodes >= 3:\n",
    "#     ip_str = ''\n",
    "#     for ip in private_ip_list:\n",
    "#         ip_str = ip_str+ ip +\":6379 \"\n",
    "#     print(ip_str)\n",
    "#     redis = TmuxSession(clients[0],'redis-serv-sess')\n",
    "#     redis.run_command('cd /home/ubuntu/redis-4.0.9/src')\n",
    "#     redis.run_command('./redis-trib.rb create '+ ip_str)\n",
    "#     redis.run_command('yes')\n",
    "#     redis.run_command('-d')\n",
    "\n",
    "if args.n_nodes >= 3:\n",
    "    ip_str = ''\n",
    "    for ip in private_ip_list:\n",
    "        ip_str = ip_str+ ip +\":6379 \"\n",
    "    print(ip_str)\n",
    "    instance = instances[0]\n",
    "    print(instance)\n",
    "    client = connect_to_instance(instance)\n",
    "    print(client)\n",
    "    commands = ['cd /home/ubuntu/redis-4.0.9/src', './redis-trib.rb create --password lsmldeeplearning '+ip_str]\n",
    "    ssh_input = ['yes']\n",
    "    inp, out,err = client.exec_command(\"\\n\".join(commands))\n",
    "    inp.write('yes\\n')\n",
    "    inp.flush()\n",
    "    output = out.read()\n",
    "    # Close down\n",
    "    out.close()\n",
    "    inp.close()\n",
    "    client.close()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Arguments String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "batch_size = 128\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 50\n",
    "num_processes = 1\n",
    "nnet_arch = 'LeNet'\n",
    "dataset = 'MNIST'\n",
    "args.is_redis = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts = ''\n",
    "for ip in private_ip_list:\n",
    "    hosts = hosts+ip+','\n",
    "hosts = hosts.strip(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset can be 'MNIST' or 'cifar10'\n",
    "#architecture can be 'LeNet' or 'ResNet'(still working on this)\n",
    "#num_processes should be either 1 or 2\n",
    "#batch size 128,256,512,1024,2048\n",
    "\n",
    "arg_str = '--is-redis='+str(args.is_redis)+' --dataset='+dataset+' --nnet-arch='+nnet_arch+' --num-processes='+ str(num_processes) + ' --batch-size='+str(batch_size) +' --lr='+str(lr) + ' --hosts='+hosts +' --epochs='+str(epochs)\n",
    "\n",
    "print(arg_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chose the log file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.is_redis:\n",
    "    log_file = dataset+'-'+nnet_arch+'-'+str(batch_size)+'-'+str(num_processes)+'-'+ 'redis'\n",
    "else:\n",
    "    log_file = dataset+'-'+nnet_arch+'-'+str(batch_size)+'-'+str(num_processes)\n",
    "print('Log file name: '+log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "running = True\n",
    "# for sess,ip in zip(tsess,private_ip_list):\n",
    "#     sess.run_command('source activate largescale')\n",
    "#     sess.run_command('~/miniconda3/envs/largescale/bin/redis-cli -h '+str(ip) +' flushall')\n",
    "#     sess.run_command('python3 -u ~/vanilla-hogwild/main.py '+arg_str+ ' 2>&1 | tee '+log_file)\n",
    "#     sess.run_command('-d')\n",
    "import select\n",
    "path = \"/Users/srujithpoondla/lsml_results/\"+str(args.n_nodes)+\"/\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "commands = ['source ~/miniconda3/bin/activate largescale']\n",
    "for i,(instance,ip) in enumerate(zip(instances,private_ip_list)):\n",
    "    redis_cli_flush = ['~/miniconda3/envs/largescale/bin/redis-cli -h -a lsmldeeplearning'+str(ip) +' flushall']\n",
    "#     train = ['nohup python3 -u ~/vanilla-hogwild/main.py '+arg_str+ ' 2>&1 | tee '+log_file+' &']\n",
    "    train = ['python3 -u ~/vanilla-hogwild/main.py '+arg_str+ '>>'+log_file+' &']\n",
    "\n",
    "    client = connect_to_instance(instance)\n",
    "#     transport = client.get_transport()\n",
    "#     channel = transport.open_session()\n",
    "    print(commands+redis_cli_flush+train)\n",
    "    client.exec_command(\"\\n\".join(commands+redis_cli_flush+train))\n",
    "#     while True:\n",
    "#         if channel.exit_status_ready():\n",
    "#             break\n",
    "# #         rl, wl, xl = select.select([channel], [], [], 0.0)\n",
    "# #         if len(rl) > 0:\n",
    "# #             print(channel.recv(1024))\n",
    "    \n",
    "#     sftp = client.open_sftp()\n",
    "#     print(path+log_file+str(i))\n",
    "#     sftp.get(log_file, path+log_file+str(i))\n",
    "#     print('copied README back here')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminate all instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sleep(100)\n",
    "# while(running):\n",
    "#     client = connect_to_instance(instances[0])\n",
    "#     inp,out,err=client.exec_command('pidof python3')\n",
    "#     out = out.read()[0]\n",
    "#     inp.close()\n",
    "#     out.close()\n",
    "#     client.close()\n",
    "#     if len(out.strip(' ').split(' ')[0])<1:\n",
    "#         for instance in instances:\n",
    "#             try:\n",
    "#                 client = connect_to_instance(instance)\n",
    "#                 out=client.exec_command('pidof python3')\n",
    "#                 print(out.read().strip(' ').split(' '))\n",
    "#                 if len(out.read().strip(' ').split(' '))>1:\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     count = count+1\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "#             if count==len(instances):\n",
    "#                 running = False\n",
    "#                 break\n",
    "#     else:\n",
    "#         sleep(30)\n",
    "        \n",
    "# path = \"/Users/srujithpoondla/lsml_results/\"+str(args.n_nodes)+\"/\"\n",
    "# if not os.path.exists(path):\n",
    "#     os.mkdir(path)\n",
    "# for i,instance in enumerate(instances):\n",
    "#     client = connect_to_instance(instance)\n",
    "#     sftp = client.open_sftp()\n",
    "#     print(path+log_file+str(i))\n",
    "#     sftp.get(log_file, path+log_file+str(i))\n",
    "#     print('copied README back here')\n",
    "#     client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for instance in instances:\n",
    "#     print(instance.terminate())\n",
    "# ec2.KeyPair('aws-key-spot-instance').delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
