{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous SGD updates using Distributed Cache Redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create spot instances\n",
    "2. Mount EFS (Not required for our project)\n",
    "3. Start redis server in all the instances and create a cluster\n",
    "4. Pull the code from github repo (https://github.com/SrujithPoondla/vanilla-hogwild.git)\n",
    "5. If need to divide the dataset between the nodes run the specific cell\n",
    "6. Run the scripts to start training\n",
    "7. After training ends close the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_setup import *\n",
    "from argparse import ArgumentParser\n",
    "import boto3\n",
    "sys.argv = ['foo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--is-redis'], dest='is_redis', nargs=0, const=True, default=True, type=None, choices=None, help='Choose whether the model to be trained using redis or not.If not using Redis, model will be trained on single process', metavar=None)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser(description='Asynchronous SGD updates using Redis')\n",
    "parser.add_argument('--n-nodes', type=int, default=1, metavar='N',\n",
    "                    help='how many aws instances to start')\n",
    "parser.add_argument('--is-redis', action='store_true', default = True,\n",
    "                    help=\"Choose whether the model to be trained using redis or not.\"\n",
    "                    \"If not using Redis, model will be trained on single process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()\n",
    "vpc_name='vpc-1b056b60'\n",
    "n_instances = args.n_nodes\n",
    "instance_type = 'm5.2xlarge'\n",
    "ami_sr = 'ami-2663e759'\n",
    "a_zone = 'us-east-1a'\n",
    "\n",
    "if args.n_nodes is 2 and args.is_redis:\n",
    "    print('Cant create a cluster with 2 redis nodes. Chose either a 3 node cluster or single instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Existing VPC by tag name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ec2.Vpc(id='vpc-1b056b60')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpc = get_vpc(vpc_name); vpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create EFS (if you haven't already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efs_tag = f'{vpc_name}-efs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efs = create_efs(efs_tag, vpc, performance_mode='maxIO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request Spot instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_name = f'{vpc_name}-instance'\n",
    "# Recommend a high compute instance as we need to do multi-threaded resizing later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot price: 0.137100, Bid price: 0.4113\n"
     ]
    }
   ],
   "source": [
    "spot_price = get_spot_prices()[instance_type]\n",
    "bid_price = \"%.4f\" % (float(spot_price)*3)\n",
    "print(f'Spot price: {spot_price}, Bid price: {bid_price}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_specs = LaunchSpecs(vpc, instance_type=instance_type, ami= ami_sr,availability_zone=a_zone).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch_specs['BlockDeviceMappings'][0]['Ebs']['VolumeSize'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BlockDeviceMappings': [{'DeviceName': '/dev/sda1',\n",
       "   'Ebs': {'DeleteOnTermination': True,\n",
       "    'VolumeSize': 20,\n",
       "    'VolumeType': 'gp2'}}],\n",
       " 'ImageId': 'ami-2663e759',\n",
       " 'InstanceType': 'm5.2xlarge',\n",
       " 'KeyName': 'aws-key-spot-instance',\n",
       " 'NetworkInterfaces': [{'AssociatePublicIpAddress': True,\n",
       "   'DeviceIndex': 0,\n",
       "   'Groups': ['sg-2624da6f'],\n",
       "   'SubnetId': 'subnet-10d9d04d'}]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launch_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ec2.Instance(id='i-01e1d14ef6b6ad5ea')]\n"
     ]
    }
   ],
   "source": [
    "ec2 = boto3.resource('ec2')\n",
    "filters = [\n",
    "    {\n",
    "        'Name': 'instance-state-name',\n",
    "        'Values': ['running']\n",
    "    }\n",
    "]\n",
    "# filter the instances based on filters() above\n",
    "ec2_instances = list(ec2.instances.filter(Filters=filters))\n",
    "instances = []\n",
    "if not len(list(ec2_instances)):\n",
    "    for i in range(n_instances):\n",
    "        instance = create_spot_instance(instance_name, launch_specs, spot_price=bid_price); \n",
    "        instances.append(instance)\n",
    "else:\n",
    "    instances = ec2_instances\n",
    "print(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@184.73.114.111'] ['184.73.114.111'] ['10.0.0.10']\n"
     ]
    }
   ],
   "source": [
    "# instance = get_instance(instance_name); instance\n",
    "ssh_commands = []\n",
    "public_ip_list = []\n",
    "private_ip_list = []\n",
    "for instance in instances:\n",
    "    # for each instance, append to lists\n",
    "    private_ip_list.append(instance.private_ip_address)\n",
    "    public_ip_list.append(instance.public_ip_address)\n",
    "    ssh_commands.append(get_ssh_command(instance))\n",
    "print(ssh_commands, public_ip_list, private_ip_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminating instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for instance in ec2_instances:\n",
    "#     print(instance.terminate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "[<paramiko.client.SSHClient object at 0x10790fda0>]\n"
     ]
    }
   ],
   "source": [
    "clients = []\n",
    "for instance in instances:\n",
    "    clients.append(connect_to_instance(instance))\n",
    "print(clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mount EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efs_addr = get_efs_address('fast-ai-efs'); efs_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = run_command(client, 'mkdir ~/efs_mount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efs_mount_cmd = f'sudo mount -t nfs -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 {efs_addr}:/ ~/efs_mount'\n",
    "# _ = run_command(client, efs_mount_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = run_command(client, 'ls efs_mount') # no reformatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tmux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<aws_setup.TmuxSession object at 0x108ec0a20>]\n"
     ]
    }
   ],
   "source": [
    "tsess = []\n",
    "for client in clients:\n",
    "    if 'sess' not in run_command(client,'tmux ls'):\n",
    "        tsess.append(TmuxSession(client, 'sess'))         \n",
    "print(tsess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activate Conda Environment in all the instances and check whether we need to create a cluster or not. Then start redis using conf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', '')\n",
      "(\"No local changes to save\\r\\nremote: Counting objects: 5, done.\\x1b[K\\r\\nremote: Compressing objects:  25% (1/4)   \\x1b[K\\rremote: Compressing objects:  50% (2/4)   \\x1b[K\\rremote: Compressing objects:  75% (3/4)   \\x1b[K\\rremote: Compressing objects: 100% (4/4)   \\x1b[K\\rremote: Compressing objects: 100% (4/4), done.\\x1b[K\\r\\nremote: Total 5 (delta 1), reused 5 (delta 1), pack-reused 0\\x1b[K\\r\\nUnpacking objects:  20% (1/5)   \\rUnpacking objects:  40% (2/5)   \\rUnpacking objects:  60% (3/5)   \\rUnpacking objects:  80% (4/5)   \\rUnpacking objects: 100% (5/5)   \\rUnpacking objects: 100% (5/5), done.\\r\\nFrom https://github.com/SrujithPoondla/vanilla-hogwild\\r\\n   a884b1c..76677b7  stable     -> origin/stable\\r\\nUpdating a884b1c..76677b7\\r\\nFast-forward\\r\\n aws_setup.py            | 361 \\x1b[32m+++++++++++++++++++++++++++\\x1b[m\\r\\n diff_models.py          |  63 \\x1b[32m+++++\\x1b[m\\r\\n download_imagenet.ipynb | 646 \\x1b[32m++++++++++++++++++++++++++++++++++++++++++++++++\\x1b[m\\r\\n 3 files changed, 1070 insertions(+)\\r\\n create mode 100644 aws_setup.py\\r\\n create mode 100644 diff_models.py\\r\\n create mode 100644 download_imagenet.ipynb\\r\\nAlready on 'stable'\\r\\nYour branch is up-to-date with 'origin/stable'.\\r\\n\", '')\n",
      "('', '')\n"
     ]
    }
   ],
   "source": [
    "for client,sess in zip(clients,tsess):\n",
    "    redis = TmuxSession(client, 'redis-sess')\n",
    "    print(run_command(client, '. ~/miniconda3/bin/activate largescale'))\n",
    "    print(run_command(client, 'cd ~/vanilla-hogwild && git stash && git pull && git checkout stable'))\n",
    "    if (args.n_nodes > 3):\n",
    "        print(redis.run_command('~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis_cluster.conf'))\n",
    "    else:\n",
    "        print(redis.run_command('~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis.conf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('OK\\r\\n', '')\n",
      "('\"1\"\\r\\n', '')\n"
     ]
    }
   ],
   "source": [
    "print(run_command(clients[0], '~/miniconda3/envs/largescale/bin/redis-cli set \\'a\\' 1'))\n",
    "print(run_command(clients[0], '~/miniconda3/envs/largescale/bin/redis-cli get \\'a\\''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create redis cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.n_nodes > 3:\n",
    "    ip_str = ''\n",
    "    for ip in private_ip_list:\n",
    "        ip_str = ip_str +\":6379 \"\n",
    "    stdin,out,err = run_command(client[0], 'cd redis-stable/src && ./redis-trib.rb create {ip_str}',['yes'])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Arguments String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 50\n",
    "num_processes = 2\n",
    "nnet_arch = 'LeNet'\n",
    "dataset = 'cifar10'\n",
    "args.is_redis = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--is-redis=True --dataset=cifar10 --nnet-arch=LeNet --num-processes=2 --batch-size=128 --lr=0.01\n"
     ]
    }
   ],
   "source": [
    "#dataset can be 'MNIST' or 'cifar10'\n",
    "#architecture can be 'LeNet' or 'ResNet'(still working on this)\n",
    "#num_processes should be either 1 or 2\n",
    "#batch size 128,256,512,1024,2048\n",
    "\n",
    "arg_str = '--is-redis='+str(args.is_redis)+' --dataset='+dataset+' --nnet-arch='+nnet_arch+' --num-processes='+\\\n",
    "str(num_processes) + ' --batch-size='+str(batch_size) +' --lr='+str(lr)\n",
    "\n",
    "print(arg_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chose the log file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.is_redis:\n",
    "    log_file = dataset+'-'+nnet_arch+'-'+str(batch_size)+'-'+str(num_processes)+'-'+ 'redis'\n",
    "else:\n",
    "    log_file = dataset+'-'+nnet_arch+'-'+str(batch_size)+'-'+str(num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sess in tsess:\n",
    "    sess.run_command('source activate largescale')\n",
    "    sess.run_command('python3 -u ~/vanilla-hogwild/main.py '+arg_str+ '2>&1 | tee '+log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
