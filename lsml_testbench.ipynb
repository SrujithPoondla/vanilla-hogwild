{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous SGD updates using Distributed Cache Redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create spot instances\n",
    "2. Mount EFS (Not required for our project)\n",
    "3. Start redis server in all the instances and create a cluster\n",
    "4. Pull the code from github repo (https://github.com/SrujithPoondla/vanilla-hogwild.git)\n",
    "5. If need to divide the dataset between the nodes run the specific cell\n",
    "6. Run the scripts to start training\n",
    "7. After training ends close the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_setup import *\n",
    "from argparse import ArgumentParser\n",
    "import boto3\n",
    "import os \n",
    "sys.argv = ['foo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--is-redis'], dest='is_redis', nargs=0, const=True, default=True, type=None, choices=None, help='Choose whether the model to be trained using redis or not.If not using Redis, model will be trained on single process', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser(description='Asynchronous SGD updates using Redis')\n",
    "parser.add_argument('--n-nodes', type=int, default=1, metavar='N',\n",
    "                    help='how many aws instances to start')\n",
    "parser.add_argument('--is-redis', action='store_true', default = True,\n",
    "                    help=\"Choose whether the model to be trained using redis or not.\"\n",
    "                    \"If not using Redis, model will be trained on single process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()\n",
    "vpc_name='vpc-1b056b60'\n",
    "args.n_nodes = 4\n",
    "n_instances = args.n_nodes\n",
    "instance_type = 'm4.10xlarge'\n",
    "ami_sr = 'ami-d70f8ea8'\n",
    "a_zone = 'us-east-1a'\n",
    "\n",
    "if args.n_nodes is 2 and args.is_redis:\n",
    "    print('Cant create a cluster with 2 redis nodes. Chose either a 3 node cluster or single instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Existing VPC by tag name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ec2.Vpc(id='vpc-1b056b60')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpc = get_vpc(vpc_name); vpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create EFS (if you haven't already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efs_tag = f'{vpc_name}-efs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efs = create_efs(efs_tag, vpc, performance_mode='maxIO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request Spot instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_name = f'{vpc_name}-instance'\n",
    "# Recommend a high compute instance as we need to do multi-threaded resizing later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot price: 0.601800, Bid price: 1.8054\n"
     ]
    }
   ],
   "source": [
    "spot_price = get_spot_prices()[instance_type]\n",
    "bid_price = \"%.4f\" % (float(spot_price)*3)\n",
    "print(f'Spot price: {spot_price}, Bid price: {bid_price}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_specs = LaunchSpecs(vpc, instance_type=instance_type, ami= ami_sr,availability_zone=a_zone).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch_specs['BlockDeviceMappings'][0]['Ebs']['VolumeSize'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BlockDeviceMappings': [{'DeviceName': '/dev/sda1',\n",
       "   'Ebs': {'DeleteOnTermination': True,\n",
       "    'VolumeSize': 20,\n",
       "    'VolumeType': 'gp2'}}],\n",
       " 'ImageId': 'ami-d70f8ea8',\n",
       " 'InstanceType': 'm4.10xlarge',\n",
       " 'KeyName': 'aws-key-spot-instance',\n",
       " 'NetworkInterfaces': [{'AssociatePublicIpAddress': True,\n",
       "   'DeviceIndex': 0,\n",
       "   'Groups': ['sg-2624da6f'],\n",
       "   'SubnetId': 'subnet-10d9d04d'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launch_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created keypair\n",
      "Waiting on spot fullfillment...\n",
      "Fulfillment completed. InstanceId: i-021239995f82d19bf\n",
      "Waiting on spot fullfillment...\n",
      "Fulfillment completed. InstanceId: i-02c139173d5bbb5c5\n",
      "Waiting on spot fullfillment...\n",
      "Fulfillment completed. InstanceId: i-02eb3d0346eab2fd6\n",
      "Waiting on spot fullfillment...\n",
      "Fulfillment completed. InstanceId: i-0fc085b5b608a075e\n",
      "Rebooting...\n",
      "Completed. SSH:  ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@54.89.57.254\n",
      "Completed. SSH:  ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@34.207.140.5\n",
      "Completed. SSH:  ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@18.232.158.114\n",
      "Completed. SSH:  ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@18.232.98.229\n",
      "[ec2.Instance(id='i-021239995f82d19bf'), ec2.Instance(id='i-02eb3d0346eab2fd6'), ec2.Instance(id='i-0fc085b5b608a075e'), ec2.Instance(id='i-02c139173d5bbb5c5')]\n"
     ]
    }
   ],
   "source": [
    "ec2 = boto3.resource('ec2')\n",
    "filters = [\n",
    "    {\n",
    "        'Name': 'instance-state-name',\n",
    "        'Values': ['running']\n",
    "    }\n",
    "]\n",
    "# filter the instances based on filters() above\n",
    "ec2_instances = list(ec2.instances.filter(Filters=filters))\n",
    "instances = []\n",
    "for instance in ec2_instances:\n",
    "    instances.append(instance)\n",
    "instances_to_request = n_instances-len(instances)\n",
    "instances = create_multiple_spot_instance(instance_name, launch_specs,instance_count=args.n_nodes, spot_price=bid_price)\n",
    "print(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@54.89.57.254', 'ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@34.207.140.5', 'ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@18.232.158.114', 'ssh -i ~/.ssh/aws-key-spot-instance.pem ubuntu@18.232.98.229'] ['54.89.57.254', '34.207.140.5', '18.232.158.114', '18.232.98.229'] ['10.0.0.12', '10.0.0.6', '10.0.0.9', '10.0.0.4']\n"
     ]
    }
   ],
   "source": [
    "# instance = get_instance(instance_name); instance\n",
    "ssh_commands = []\n",
    "public_ip_list = []\n",
    "private_ip_list = []\n",
    "for instance in instances:\n",
    "    # for each instance, append to lists\n",
    "    private_ip_list.append(instance.private_ip_address)\n",
    "    public_ip_list.append(instance.public_ip_address)\n",
    "    ssh_commands.append(get_ssh_command(instance))\n",
    "print(ssh_commands, public_ip_list, private_ip_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminating instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for instance in instances:\n",
    "#     print(instance.terminate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activate Conda Environment in all the instances and check whether we need to create a cluster or not. Then start redis using conf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Exception: timed out Retrying...\n",
      "Exception: timed out Retrying...\n",
      "Connected!\n",
      "b\"No local changes to save\\nUpdating 2c6955b..0f8465d\\nFast-forward\\n aws_setup.py         |   3 +-\\n lsml_testbench.ipynb | 503 +++++++++++++++++++++++----------------------------\\n train.py             |   4 +-\\n 3 files changed, 230 insertions(+), 280 deletions(-)\\nYour branch is up-to-date with 'origin/stable'.\\ncifar10_data\\nlargescale.yml\\nminiconda3\\nmnist_data\\nredis-4.0.9\\nredis-conf\\nredis-ml\\nvanilla-hogwild\\n\"\n",
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "b\"No local changes to save\\nUpdating 2c6955b..0f8465d\\nFast-forward\\n aws_setup.py         |   3 +-\\n lsml_testbench.ipynb | 503 +++++++++++++++++++++++----------------------------\\n train.py             |   4 +-\\n 3 files changed, 230 insertions(+), 280 deletions(-)\\nYour branch is up-to-date with 'origin/stable'.\\ncifar10_data\\nlargescale.yml\\nminiconda3\\nmnist_data\\nredis-4.0.9\\nredis-conf\\nredis-ml\\nvanilla-hogwild\\n\"\n",
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "b\"No local changes to save\\nUpdating 2c6955b..0f8465d\\nFast-forward\\n aws_setup.py         |   3 +-\\n lsml_testbench.ipynb | 503 +++++++++++++++++++++++----------------------------\\n train.py             |   4 +-\\n 3 files changed, 230 insertions(+), 280 deletions(-)\\nYour branch is up-to-date with 'origin/stable'.\\ncifar10_data\\nlargescale.yml\\nminiconda3\\nmnist_data\\nredis-4.0.9\\nredis-conf\\nredis-ml\\nvanilla-hogwild\\n\"\n",
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "b\"No local changes to save\\nUpdating 2c6955b..0f8465d\\nFast-forward\\n aws_setup.py         |   3 +-\\n lsml_testbench.ipynb | 503 +++++++++++++++++++++++----------------------------\\n train.py             |   4 +-\\n 3 files changed, 230 insertions(+), 280 deletions(-)\\nYour branch is up-to-date with 'origin/stable'.\\ncifar10_data\\nlargescale.yml\\nminiconda3\\nmnist_data\\nredis-4.0.9\\nredis-conf\\nredis-ml\\nvanilla-hogwild\\n\"\n"
     ]
    }
   ],
   "source": [
    "# for client,ip in zip(clients,private_ip_list):\n",
    "#     if 'redis' not in run_command(client,'tmux ls'):\n",
    "#         redis = TmuxSession(client, 'redis-sess')\n",
    "#     run_command(client, 'cd ~/vanilla-hogwild && git stash && git pull && git checkout stable')\n",
    "#     if (args.n_nodes >= 3):\n",
    "#         redis.run_command('rm dump.rdb && rm appendonly.aof && rm nodes-6379.conf')\n",
    "#         redis.run_command('echo bind '+ip+'>> ~/redis-conf/redis_cluster.conf')\n",
    "#         print(redis.run_command('nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis_cluster.conf &'))\n",
    "#         redis.run_command('-d')\n",
    "#     else:\n",
    "#         redis.run_command('echo bind '+ip+'>> ~/redis-conf/redis_cluster.conf')\n",
    "#         redis.run_command('rm dump.rdb && rm appendonly.aof && rm nodes-6379.conf')\n",
    "#         print(redis.run_command('~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis.conf'))\n",
    "#         redis.run_command('-d')\n",
    "\n",
    "# for client,ip in zip(clients,private_ip_list):\n",
    "#     run_command(client, 'cd ~/vanilla-hogwild && git stash && git pull && git checkout stable')\n",
    "#     if (args.n_nodes >= 3):\n",
    "#         run_command(client,'cd /home/ubuntu/ && rm dump.rdb && rm appendonly.aof && rm nodes-6379.conf')\n",
    "#         run_command(client,'echo bind '+ip+'>> ~/redis-conf/redis_cluster.conf')\n",
    "#         print(run_command(client, 'nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis_cluster.conf &'))\n",
    "#     else:\n",
    "#         run_command(client,'cd /home/ubuntu/ && rm dump.rdb && rm appendonly.aof && rm nodes-6379.conf')\n",
    "#         print(run_command(client, 'nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis.conf &'))\n",
    "\n",
    "commands = ['cd ~/vanilla-hogwild', 'git stash', 'git pull' ,'git checkout stable',\n",
    "            'rm -rf ~/redis-data', 'cd ~','ls' ,'mkdir redis-data']\n",
    "\n",
    "for instance,pr_ip in zip(instances,private_ip_list):\n",
    "    client = connect_to_instance(instance)\n",
    "    if (args.n_nodes >= 3):\n",
    "        indep_commands = ['echo bind '+pr_ip+'>> ~/redis-conf/redis_cluster.conf',\n",
    "                          'requirepass lsmldeeplearning',\n",
    "            'nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis_cluster.conf >\\\n",
    "                          /home/ubuntu/redis-data/redis-log.out &']\n",
    "    else:\n",
    "        indep_commands = ['requirepass lsmldeeplearning','nohup ~/miniconda3/envs/largescale/bin/redis-server ~/redis-conf/redis.conf > \\\n",
    "                          /home/ubuntu/redis-data/redis-log.out &']\n",
    "    commands = commands + indep_commands\n",
    "    inp, out,err = client.exec_command(\"\\n\".join(commands))\n",
    "#     sleep(5)\n",
    "    inp.write('\\n')\n",
    "    inp.flush()\n",
    "    output = out.read()\n",
    "    # Close down\n",
    "    out.close()\n",
    "    inp.close()\n",
    "    client.close()\n",
    "    print(output)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create redis cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0.0.12:6379 10.0.0.6:6379 10.0.0.9:6379 10.0.0.4:6379 \n",
      "ec2.Instance(id='i-021239995f82d19bf')\n",
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "<paramiko.client.SSHClient object at 0x10e538828>\n",
      "b\">>> Creating cluster\\n>>> Performing hash slots allocation on 4 nodes...\\nUsing 4 masters:\\n10.0.0.12:6379\\n10.0.0.6:6379\\n10.0.0.9:6379\\n10.0.0.4:6379\\nM: 462df4695b4d2d7084a7abe80334376a517bb6af 10.0.0.12:6379\\n   slots:0-4095 (4096 slots) master\\nM: de01f37ad5259f1491633940ff7469937ed9078d 10.0.0.6:6379\\n   slots:4096-8191 (4096 slots) master\\nM: aeaf8666b9daa44243558b513ccb71ae08bd5d4c 10.0.0.9:6379\\n   slots:8192-12287 (4096 slots) master\\nM: d9ce7d22cd1f2f1076fc2703eb5e3f7bdef76410 10.0.0.4:6379\\n   slots:12288-16383 (4096 slots) master\\nCan I set the above configuration? (type 'yes' to accept): >>> Nodes configuration updated\\n>>> Assign a different config epoch to each node\\n>>> Sending CLUSTER MEET messages to join the cluster\\nWaiting for the cluster to join...\\n>>> Performing Cluster Check (using node 10.0.0.12:6379)\\nM: 462df4695b4d2d7084a7abe80334376a517bb6af 10.0.0.12:6379\\n   slots:0-4095 (4096 slots) master\\n   0 additional replica(s)\\nM: de01f37ad5259f1491633940ff7469937ed9078d 10.0.0.6:6379\\n   slots:4096-8191 (4096 slots) master\\n   0 additional replica(s)\\nM: aeaf8666b9daa44243558b513ccb71ae08bd5d4c 10.0.0.9:6379\\n   slots:8192-12287 (4096 slots) master\\n   0 additional replica(s)\\nM: d9ce7d22cd1f2f1076fc2703eb5e3f7bdef76410 10.0.0.4:6379\\n   slots:12288-16383 (4096 slots) master\\n   0 additional replica(s)\\n[OK] All nodes agree about slots configuration.\\n>>> Check for open slots...\\n>>> Check slots coverage...\\n[OK] All 16384 slots covered.\\n\"\n"
     ]
    }
   ],
   "source": [
    "# if args.n_nodes >= 3:\n",
    "#     ip_str = ''\n",
    "#     for ip in private_ip_list:\n",
    "#         ip_str = ip_str+ ip +\":6379 \"\n",
    "#     print(ip_str)\n",
    "#     redis = TmuxSession(clients[0],'redis-serv-sess')\n",
    "#     redis.run_command('cd /home/ubuntu/redis-4.0.9/src')\n",
    "#     redis.run_command('./redis-trib.rb create '+ ip_str)\n",
    "#     redis.run_command('yes')\n",
    "#     redis.run_command('-d')\n",
    "\n",
    "if args.n_nodes >= 3:\n",
    "    ip_str = ''\n",
    "    for ip in private_ip_list:\n",
    "        ip_str = ip_str+ ip +\":6379 \"\n",
    "    print(ip_str)\n",
    "    instance = instances[0]\n",
    "    print(instance)\n",
    "    client = connect_to_instance(instance)\n",
    "    print(client)\n",
    "    commands = ['cd /home/ubuntu/redis-4.0.9/src', './redis-trib.rb create '+ip_str]\n",
    "    ssh_input = ['yes']\n",
    "    inp, out,err = client.exec_command(\"\\n\".join(commands))\n",
    "    inp.write('yes\\n')\n",
    "    inp.flush()\n",
    "    output = out.read()\n",
    "    # Close down\n",
    "    out.close()\n",
    "    inp.close()\n",
    "    client.close()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Arguments String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "batch_size = 128\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 50\n",
    "num_processes = 1\n",
    "nnet_arch = 'LeNet'\n",
    "dataset = 'MNIST'\n",
    "args.is_redis = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts = ''\n",
    "for ip in private_ip_list:\n",
    "    hosts = hosts+ip+','\n",
    "hosts = hosts.strip(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--is-redis=True --dataset=MNIST --nnet-arch=LeNet --num-processes=1 --batch-size=128 --lr=0.01 --hosts=10.0.0.12,10.0.0.6,10.0.0.9,10.0.0.4 --epochs=1\n"
     ]
    }
   ],
   "source": [
    "#dataset can be 'MNIST' or 'cifar10'\n",
    "#architecture can be 'LeNet' or 'ResNet'(still working on this)\n",
    "#num_processes should be either 1 or 2\n",
    "#batch size 128,256,512,1024,2048\n",
    "\n",
    "arg_str = '--is-redis='+str(args.is_redis)+' --dataset='+dataset+' --nnet-arch='+nnet_arch+' --num-processes='+ str(num_processes) + ' --batch-size='+str(batch_size) +' --lr='+str(lr) + ' --hosts='+hosts +' --epochs='+str(epochs)\n",
    "\n",
    "print(arg_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chose the log file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file name: MNIST-LeNet-128-1-redis\n"
     ]
    }
   ],
   "source": [
    "if args.is_redis:\n",
    "    log_file = dataset+'-'+nnet_arch+'-'+str(batch_size)+'-'+str(num_processes)+'-'+ 'redis'\n",
    "else:\n",
    "    log_file = dataset+'-'+nnet_arch+'-'+str(batch_size)+'-'+str(num_processes)\n",
    "print('Log file name: '+log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "['source ~/miniconda3/bin/activate largescale', '~/miniconda3/envs/largescale/bin/redis-cli -h 10.0.0.12 flushall', 'python3 -u ~/vanilla-hogwild/main.py --is-redis=True --dataset=MNIST --nnet-arch=LeNet --num-processes=1 --batch-size=128 --lr=0.01 --hosts=10.0.0.12,10.0.0.6,10.0.0.9,10.0.0.4 --epochs=1>>MNIST-LeNet-128-1-redis &']\n",
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "['source ~/miniconda3/bin/activate largescale', '~/miniconda3/envs/largescale/bin/redis-cli -h 10.0.0.6 flushall', 'python3 -u ~/vanilla-hogwild/main.py --is-redis=True --dataset=MNIST --nnet-arch=LeNet --num-processes=1 --batch-size=128 --lr=0.01 --hosts=10.0.0.12,10.0.0.6,10.0.0.9,10.0.0.4 --epochs=1>>MNIST-LeNet-128-1-redis &']\n",
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "['source ~/miniconda3/bin/activate largescale', '~/miniconda3/envs/largescale/bin/redis-cli -h 10.0.0.9 flushall', 'python3 -u ~/vanilla-hogwild/main.py --is-redis=True --dataset=MNIST --nnet-arch=LeNet --num-processes=1 --batch-size=128 --lr=0.01 --hosts=10.0.0.12,10.0.0.6,10.0.0.9,10.0.0.4 --epochs=1>>MNIST-LeNet-128-1-redis &']\n",
      "Connecting to SSH...\n",
      "Got client\n",
      "/Users/srujithpoondla/.ssh/aws-key-spot-instance.pem\n",
      "Connected!\n",
      "['source ~/miniconda3/bin/activate largescale', '~/miniconda3/envs/largescale/bin/redis-cli -h 10.0.0.4 flushall', 'python3 -u ~/vanilla-hogwild/main.py --is-redis=True --dataset=MNIST --nnet-arch=LeNet --num-processes=1 --batch-size=128 --lr=0.01 --hosts=10.0.0.12,10.0.0.6,10.0.0.9,10.0.0.4 --epochs=1>>MNIST-LeNet-128-1-redis &']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "running = True\n",
    "# for sess,ip in zip(tsess,private_ip_list):\n",
    "#     sess.run_command('source activate largescale')\n",
    "#     sess.run_command('~/miniconda3/envs/largescale/bin/redis-cli -h '+str(ip) +' flushall')\n",
    "#     sess.run_command('python3 -u ~/vanilla-hogwild/main.py '+arg_str+ ' 2>&1 | tee '+log_file)\n",
    "#     sess.run_command('-d')\n",
    "import select\n",
    "path = \"/Users/srujithpoondla/lsml_results/\"+str(args.n_nodes)+\"/\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "commands = ['source ~/miniconda3/bin/activate largescale']\n",
    "for i,(instance,ip) in enumerate(zip(instances,private_ip_list)):\n",
    "    redis_cli_flush = ['~/miniconda3/envs/largescale/bin/redis-cli -h '+str(ip) +' flushall']\n",
    "#     train = ['nohup python3 -u ~/vanilla-hogwild/main.py '+arg_str+ ' 2>&1 | tee '+log_file+' &']\n",
    "    train = ['python3 -u ~/vanilla-hogwild/main.py '+arg_str+ '>>'+log_file+' &']\n",
    "\n",
    "    client = connect_to_instance(instance)\n",
    "#     transport = client.get_transport()\n",
    "#     channel = transport.open_session()\n",
    "    print(commands+redis_cli_flush+train)\n",
    "    client.exec_command(\"\\n\".join(commands+redis_cli_flush+train))\n",
    "#     while True:\n",
    "#         if channel.exit_status_ready():\n",
    "#             break\n",
    "# #         rl, wl, xl = select.select([channel], [], [], 0.0)\n",
    "# #         if len(rl) > 0:\n",
    "# #             print(channel.recv(1024))\n",
    "    \n",
    "#     sftp = client.open_sftp()\n",
    "#     print(path+log_file+str(i))\n",
    "#     sftp.get(log_file, path+log_file+str(i))\n",
    "#     print('copied README back here')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminate all instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TerminatingInstances': [{'CurrentState': {'Code': 32, 'Name': 'shutting-down'}, 'InstanceId': 'i-021239995f82d19bf', 'PreviousState': {'Code': 16, 'Name': 'running'}}], 'ResponseMetadata': {'RequestId': '6528483e-4ee6-4165-b0d9-684331ac9127', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'text/xml;charset=UTF-8', 'transfer-encoding': 'chunked', 'vary': 'Accept-Encoding', 'date': 'Mon, 07 May 2018 02:50:20 GMT', 'server': 'AmazonEC2'}, 'RetryAttempts': 0}}\n",
      "{'TerminatingInstances': [{'CurrentState': {'Code': 32, 'Name': 'shutting-down'}, 'InstanceId': 'i-02eb3d0346eab2fd6', 'PreviousState': {'Code': 16, 'Name': 'running'}}], 'ResponseMetadata': {'RequestId': '44ef67bd-990d-4727-ad10-fa5a4209e0c6', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'text/xml;charset=UTF-8', 'transfer-encoding': 'chunked', 'vary': 'Accept-Encoding', 'date': 'Mon, 07 May 2018 02:50:20 GMT', 'server': 'AmazonEC2'}, 'RetryAttempts': 0}}\n",
      "{'TerminatingInstances': [{'CurrentState': {'Code': 32, 'Name': 'shutting-down'}, 'InstanceId': 'i-0fc085b5b608a075e', 'PreviousState': {'Code': 16, 'Name': 'running'}}], 'ResponseMetadata': {'RequestId': '5271d64f-930d-4d3c-825e-16445cad4b81', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'text/xml;charset=UTF-8', 'transfer-encoding': 'chunked', 'vary': 'Accept-Encoding', 'date': 'Mon, 07 May 2018 02:50:21 GMT', 'server': 'AmazonEC2'}, 'RetryAttempts': 0}}\n",
      "{'TerminatingInstances': [{'CurrentState': {'Code': 32, 'Name': 'shutting-down'}, 'InstanceId': 'i-02c139173d5bbb5c5', 'PreviousState': {'Code': 16, 'Name': 'running'}}], 'ResponseMetadata': {'RequestId': 'ca08e86f-3d88-4c09-9026-953101496bbb', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'text/xml;charset=UTF-8', 'transfer-encoding': 'chunked', 'vary': 'Accept-Encoding', 'date': 'Mon, 07 May 2018 02:50:21 GMT', 'server': 'AmazonEC2'}, 'RetryAttempts': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'HTTPHeaders': {'content-length': '227',\n",
       "   'content-type': 'text/xml;charset=UTF-8',\n",
       "   'date': 'Mon, 07 May 2018 02:50:21 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': 'f03446fc-b327-4fa7-bb17-c082d684f126',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(100)\n",
    "while(running):\n",
    "    client = connect_to_instance(instances[0])\n",
    "    inp,out,err=client.exec_command('pidof python3')\n",
    "    out = out.read()[0]\n",
    "    inp.close()\n",
    "    out.close()\n",
    "    client.close()\n",
    "    if len(out.strip(' ').split(' ')[0])<1:\n",
    "        for instance in instances:\n",
    "            try:\n",
    "                client = connect_to_instance(instance)\n",
    "                out=client.exec_command('pidof python3')\n",
    "                if len(out.read().strip(' ').split(' ')[0])>1:\n",
    "                    continue\n",
    "                else:\n",
    "                    count = count+1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            if count==len(instances):\n",
    "                running = False\n",
    "                break\n",
    "    else:\n",
    "        sleep(30)\n",
    "        \n",
    "path = \"/Users/srujithpoondla/lsml_results/\"+str(args.n_nodes)+\"/\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "for i,instance in enumerate(instances):\n",
    "    client = connect_to_instance(instance)\n",
    "    sftp = client.open_sftp()\n",
    "    print(path+log_file+str(i))\n",
    "    sftp.get(log_file, path+log_file+str(i))\n",
    "    print('copied README back here')\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
